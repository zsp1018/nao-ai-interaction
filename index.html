<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>基于 AI 交互的 儿童陪伴机器人 Demo</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif; line-height: 1.6; color: #24292e; max-width: 900px; margin: 0 auto; padding: 20px; }
        h1, h2, h3 { border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; margin-top: 1.5em; }
        code { background-color: #f6f8fa; padding: 0.2em 0.4em; border-radius: 3px; font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace; font-size: 0.9em; }
        pre { background-color: #f6f8fa; padding: 16px; overflow: auto; border-radius: 3px; }
        .highlight-box { background-color: #e8f3ff; border: 1px solid #0366d6; border-radius: 6px; padding: 20px; margin-bottom: 20px; }
        .highlight-box h2 { margin-top: 0; border-bottom: none; color: #0366d6; }
        .highlight-box ul { margin-bottom: 0; padding-left: 20px; }
        .highlight-box li { margin-bottom: 10px; }
        .timeline-event { border-left: 4px solid #0366d6; padding-left: 20px; margin-left: 5px; margin-bottom: 30px; }
        .timeline-date { font-weight: bold; color: #586069; font-size: 0.9em; margin-bottom: 5px; display: block; }
        .timeline-content img { max-width: 100%; border: 1px solid #e1e4e8; border-radius: 6px; margin-top: 10px; box-shadow: 0 2px 6px rgba(0,0,0,0.1); }
        a { color: #0366d6; text-decoration: none; }
        a:hover { text-decoration: underline; }
        img { max-width: 100%; border-radius: 4px; }
        .center { text-align: center; }
    </style>
</head>
<body>

<h1>基于 AI 交互的 儿童陪伴机器人🧸Demo</h1>

<p>本项目利用电脑部署本地大语言模型 (Llama 3) 作为Nao 机器人的外置大脑，赋予智能语音交互和动作控制能力。</p>

<!-- 重点强调部分 -->
<div class="highlight-box">
    <h2> 项目核心亮点</h2>
    <ul>
        <li>
            <strong>项目缘由：Thor 的前瞻验证</strong><br>
            经过调研，我们发现 <strong>Thor</strong> 是一款非常适合人形机器人的高性能计算平台。为了快速启动研发，本项目目前使用高性能<strong>个人电脑 (PC)</strong> 作为 Thor 的“平替”方案进行初期开发和技术验证。
        </li>
        <li>
            <strong>从小模型到大模型的进化</strong><br>
            当前在 PC 平替方案上，我们成功部署并运行了 <strong>8B 参数量</strong>的小型模型（Llama 3）。这是一个起点，未来迁移至算力更强大的 <strong>Thor</strong> 平台后，我们将能够本地部署高达 <strong>70B 参数量</strong>的大模型，实现质的飞跃。
        </li>
        <li>
            <strong>同源 Linux 架构，从 0 开始</strong><br>
            本项目完全<strong>从 0 开始构建</strong>，且底层特意选用了与 Thor 一致的 <strong>Linux 操作系统</strong>，确保未来从 PC 向 Thor 平台迁移时能够无缝衔接。
        </li>
        <li>
            <strong>🛡️ 完全本地部署，无需联网</strong><br>
            核心优势之一是实现了 <strong>100% 本地化运行</strong>。语音识别、语义理解、动作控制等所有计算均在本地完成，<strong>无需互联网连接</strong>，确保了极低延迟和绝对的数据隐私。
        </li>
    </ul>
</div>

<h2> 项目时间节点</h2>

<div class="timeline-event">
    <span class="timeline-date">2025年11月26日 — 项目启动与环境构建</span>
    <div class="timeline-content">
        <p>11月26日完成了机器人控制端与 AI 大脑端的底层环境搭建。</p>
        
        <h4>1. Naoqi SDK 安装 (18:51)</h4>
        <p>
            完成 Nao 机器人 Python 2.7 控制环境的下载与配置。
            <br>
            <em>如下图所示，<code>pynaoqi</code> SDK 包于 18:51 下载完毕：</em>
        </p>
        <!-- 请将您提供的第二张图片重命名为 naoqi_setup.png 并放在同一目录下 -->
        <img src="naoqi_setup.png" alt="Naoqi SDK 安装时间截图: 2025-11-26 18:51">

        <h4>2. Llama 3 模型部署 (21:29)</h4>
        <p>
            完成 Ollama 本地推理环境搭建及 Llama 3 (8B) 模型权重的拉取。
            <br>
            <em>如下图所示，模型文件 <code>manifest</code> 于 21:29 创建，标志着本地 AI 大脑部署完成：</em>
        </p>
        <!-- 请将您提供的第一张图片重命名为 llama_setup.png 并放在同一目录下 -->
        <img src="llama_setup.png" alt="Llama 3 模型部署时间截图: 2025-11-26 21:29">
    </div>
</div>

<h2>演示视频</h2>
<p class="center">
  <a href="https://www.bilibili.com/video/BV12NSMBREwr/?spm_id_from=333.337.search-card.all.click&vd_source=e624924603cde403f14272de3d1eea6f" target="_blank">
    <img src="https://github.com/zsp1018/nao-ai-interaction/raw/main/talk.gif" width="400" alt="演示视频预览" title="点击观看 Bilibili 演示视频">
  </a>
  <br>
  <br>
  <a href="https://www.bilibili.com/video/BV12NSMBREwr/?spm_id_from=333.337.search-card.all.click&vd_source=e624924603cde403f14272de3d1eea6f" target="_blank" style="font-weight: bold; font-size: 1.1em;">
    👉 点击此处观看完整演示视频 (Bilibili)
  </a>
</p>

<h2> 功能特性</h2>
<ul>
    <li><strong>语音交互</strong>：直接与 Nao 对话，使用本地语音识别 (Vosk) 听懂你的指令。</li>
    <li><strong>AI 大脑</strong>：由 Llama 3 (通过 Ollama 运行) 驱动，理解上下文并生成自然的回复。</li>
    <li><strong>动作控制</strong>：根据对话内容自动执行动作（如挥手、走路、坐下、打太极、弹吉他等）。</li>
    <li><strong>情感表达</strong>：通过眼睛灯光颜色和肢体语言表达情感（开心、难过、害怕、害羞）。</li>
    <li><strong>变声功能</strong>：通过语音指令改变 Nao 的音调（变成小黄人、怪兽、甜美女生等）。</li>
</ul>

<h2> 环境要求</h2>
<ol>
    <li><strong>硬件</strong>：Nao 机器人（需与电脑连接在同一 Wi-Fi 下）。</li>
    <li><strong>软件</strong>：
        <ul>
            <li><strong>Ollama</strong>：已安装并运行 <code>llama3</code> 模型 (<code>ollama pull llama3</code>)。</li>
            <li><strong>Conda</strong>：用于管理 Python 环境。</li>
            <li><strong>Naoqi SDK</strong>：Nao 机器人的 Python 2.7 SDK。</li>
        </ul>
    </li>
</ol>

<h2> 安装步骤</h2>
<ol>
    <li><strong>环境配置</strong>：
        <ul>
            <li>创建 Python 3 环境 (<code>ai_env</code>) 用于运行 AI 大脑：
<pre><code>conda create -n ai_env python=3.10
conda activate ai_env
pip install ollama sounddevice vosk</code></pre>
            </li>
            <li>创建 Python 2.7 环境 (<code>naoqi</code>) 用于控制 Nao：
<pre><code>conda create -n naoqi python=2.7
# 请手动安装 Naoqi SDK 并配置 PYTHONPATH</code></pre>
            </li>
        </ul>
    </li>
    <li><strong>下载模型</strong>：
        <ul>
            <li>下载 Vosk 语音识别模型（推荐 <code>vosk-model-small-cn-0.22</code>），解压并重命名为 <code>model/</code> 文件夹，放在项目根目录下。</li>
        </ul>
    </li>
    <li><strong>修改配置</strong>：
        <ul>
            <li>修改 <code>nao_body_listen.py</code>：将 <code>ROBOT_IP</code> 改为你 Nao 的实际 IP 地址。</li>
            <li>修改 <code>ai_brain_voice.py</code>：确保 <code>HOST</code> 和 <code>PORT</code> 配置正确。</li>
        </ul>
    </li>
</ol>

<h2> 使用方法</h2>
<p>运行启动脚本，将在不同终端中自动启动所有服务：</p>
<pre><code>./start_all.sh</code></pre>

<p>或者手动分步运行：</p>
<ol>
    <li><strong>终端 1 (Ollama 服务)</strong>: <code>ollama serve</code></li>
    <li><strong>终端 2 (AI 大脑)</strong>: <code>python ai_brain_voice.py</code> (需在 <code>ai_env</code> 环境下)</li>
    <li><strong>终端 3 (Nao 身体)</strong>: <code>python nao_body_listen.py</code> (需在 <code>naoqi</code> 环境下)</li>
</ol>

<h2>💬 指令示例</h2>
<p>试着对 Nao 说：</p>
<ul>
    <li>“你好”</li>
    <li>“教我学英语”</li>
    <li>“向前走”</li>
    <li>“坐下”</li>
    <li>“做一个开心的表情”</li>
    <li>“弹个吉他”</li>
    <li>“打太极”</li>
    <li>“变成小黄人的声音”</li>
</ul>

</body>
</html>